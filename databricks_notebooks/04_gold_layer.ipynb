{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gl-md-0001",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "gl-md-0001",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Gold Layer: Analytics & Aggregations\n",
    "\n",
    "## Purpose\n",
    "Read cleaned data from the Silver Delta table and produce aggregated analytics\n",
    "fact tables for dashboards, reporting, and alerting.\n",
    "\n",
    "## Data Flow\n",
    "```\n",
    "Silver Delta Table (Clean) -> Aggregate -> Gold Fact Tables (Analytics)\n",
    "```\n",
    "\n",
    "## Outputs\n",
    "| Table | Description |\n",
    "|---|---|\n",
    "| `gold_fraud_summary` | Fraud vs Legitimate totals and Amount stats |\n",
    "| `gold_hourly_patterns` | Hourly transaction counts with watermark |\n",
    "| `gold_high_value_alerts` | High-value alerts with severity levels |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gl-md-0002",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "gl-md-0002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Cleanup (Optional)\n",
    "\n",
    "Run this cell to **reset the Gold tables and checkpoints** before a fresh start.\n",
    "Skip this cell if you want to keep existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "gl-code-0001",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "gl-code-0001",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Stop active streams\n",
    "for s in spark.streams.active:\n",
    "    s.stop()\n",
    "print(\"All active streams stopped.\")\n",
    "\n",
    "# 2. Drop the Gold summary table\n",
    "try:\n",
    "    spark.sql(\"DROP TABLE IF EXISTS fraud_lakehouse_workspace.default.gold_fraud_summary\")\n",
    "    print(\"Gold summary table dropped.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to drop Gold summary table: {e}\")\n",
    "\n",
    "# 3. Delete the Gold checkpoint\n",
    "gold_checkpoint = \"YOUR_CHECKPOINT_PATH_HERE\" # Replace with your actual checkpoint path, e.g., \"dbfs:/fraud_lakehouse_workspace/checkpoints/gold_summary_checkpoint\"\n",
    "try:\n",
    "    dbutils.fs.rm(gold_checkpoint, recurse=True)\n",
    "    print(\"Gold checkpoint cleared.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to clear Gold checkpoint: {e}\")\n",
    "\n",
    "print(\"Gold slate is clean. Ready to rebuild analytics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gl-md-0003",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "gl-md-0003",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Gold Layer - Build All Fact Tables\n",
    "\n",
    "This cell builds three Gold analytics tables from the Silver stream:\n",
    "\n",
    "| Table | Output Mode | Description |\n",
    "|---|---|---|\n",
    "| `gold_fraud_summary` | Complete | Fraud vs Legitimate totals, avg/min/max/sum of Amount |\n",
    "| `gold_hourly_patterns` | Append | Hourly transaction counts and amounts with watermark |\n",
    "| `gold_high_value_alerts` | Append | Alerts for transactions over 1000 with severity |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "gl-code-0002",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "gl-code-0002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Define checkpoint paths\n",
    "gold_checkpoint_summary = \"YOUR_CHECKPOINT_PATH_HERE\" # Replace with your actual checkpoint path, e.g., \"dbfs:/fraud_lakehouse_workspace/checkpoints/gold_summary_checkpoint\"\n",
    "gold_checkpoint_hourly = \"YOUR_CHECKPOINT_PATH_HERE\" # Replace with your actual checkpoint path, e.g., \"dbfs:/fraud_lakehouse_workspace/checkpoints/gold_hourly\"\n",
    "gold_checkpoint_alerts = \"YOUR_CHECKPOINT_PATH_HERE\" # Replace with your actual checkpoint path, e.g., \"dbfs:/fraud_lakehouse_workspace/checkpoints/gold_alerts\"\n",
    "\n",
    "print(\"Building Gold Layer (Multiple Fact Tables)...\")\n",
    "\n",
    "# Read from Silver\n",
    "try:\n",
    "    df_silver_stream = spark.readStream \\\n",
    "        .table(\"fraud_lakehouse_workspace.default.silver_transactions\")\n",
    "    print(\"Connected to Silver stream.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Silver stream: {e}\")\n",
    "    raise\n",
    "\n",
    "# ========================================\n",
    "# GOLD TABLE 1: Fraud Summary by Class\n",
    "# ========================================\n",
    "try:\n",
    "    df_gold_summary = df_silver_stream \\\n",
    "        .groupBy(\"Class\") \\\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"total_transactions\"),\n",
    "            avg(\"Amount\").alias(\"avg_amount\"),\n",
    "            min(\"Amount\").alias(\"min_amount\"),\n",
    "            max(\"Amount\").alias(\"max_amount\"),\n",
    "            sum(\"Amount\").alias(\"total_amount\")\n",
    "        )\n",
    "\n",
    "    query_summary = df_gold_summary.writeStream \\\n",
    "        .format(\"delta\") \\\n",
    "        .outputMode(\"complete\") \\\n",
    "        .option(\"checkpointLocation\", gold_checkpoint_summary) \\\n",
    "        .toTable(\"fraud_lakehouse_workspace.default.gold_fraud_summary\")\n",
    "\n",
    "    print(\"Gold Summary table streaming!\")\n",
    "except Exception as e:\n",
    "    print(f\"Gold Summary table failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# ========================================\n",
    "# GOLD TABLE 2: Hourly Transaction Patterns (WITH WATERMARK)\n",
    "# ========================================\n",
    "try:\n",
    "    df_gold_hourly = df_silver_stream \\\n",
    "        .withWatermark(\"silver_processed_time\", \"10 minutes\") \\\n",
    "        .groupBy(\n",
    "            col(\"transaction_date\"),\n",
    "            col(\"transaction_hour\"),\n",
    "            col(\"Class\"),\n",
    "            window(col(\"silver_processed_time\"), \"1 hour\")\n",
    "        ) \\\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"transaction_count\"),\n",
    "            avg(\"Amount\").alias(\"avg_amount\"),\n",
    "            sum(\"Amount\").alias(\"total_amount\"),\n",
    "            sum(\"is_high_value\").alias(\"high_value_count\")\n",
    "        ) \\\n",
    "        .select(\n",
    "            col(\"transaction_date\"),\n",
    "            col(\"transaction_hour\"),\n",
    "            col(\"Class\"),\n",
    "            col(\"window.start\").alias(\"window_start\"),\n",
    "            col(\"window.end\").alias(\"window_end\"),\n",
    "            col(\"transaction_count\"),\n",
    "            col(\"avg_amount\"),\n",
    "            col(\"total_amount\"),\n",
    "            col(\"high_value_count\")\n",
    "        ) \\\n",
    "        .withColumn(\"gold_created_time\", current_timestamp())\n",
    "\n",
    "    query_hourly = df_gold_hourly.writeStream \\\n",
    "        .format(\"delta\") \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .option(\"checkpointLocation\", gold_checkpoint_hourly) \\\n",
    "        .toTable(\"fraud_lakehouse_workspace.default.gold_hourly_patterns\")\n",
    "\n",
    "    print(\"Gold Hourly Patterns table streaming!\")\n",
    "except Exception as e:\n",
    "    print(f\"Gold Hourly Patterns table failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# ========================================\n",
    "# GOLD TABLE 3: High-Value Alerts (NO AGGREGATION - NO WATERMARK NEEDED)\n",
    "# ========================================\n",
    "try:\n",
    "    df_gold_alerts = df_silver_stream \\\n",
    "        .filter(col(\"is_high_value\") == 1) \\\n",
    "        .select(\n",
    "            col(\"Time\"),\n",
    "            col(\"transaction_date\"),\n",
    "            col(\"transaction_hour\"),\n",
    "            col(\"Amount\"),\n",
    "            col(\"Class\"),\n",
    "            col(\"is_fraud\"),\n",
    "            col(\"amount_category\"),\n",
    "            col(\"silver_processed_time\")\n",
    "        ) \\\n",
    "        .withColumn(\"alert_severity\",\n",
    "                    when(col(\"Amount\") > 5000, \"Critical\")\n",
    "                    .when(col(\"Amount\") > 2000, \"High\")\n",
    "                    .otherwise(\"Medium\"))\n",
    "\n",
    "    query_alerts = df_gold_alerts.writeStream \\\n",
    "        .format(\"delta\") \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .option(\"checkpointLocation\", gold_checkpoint_alerts) \\\n",
    "        .toTable(\"fraud_lakehouse_workspace.default.gold_high_value_alerts\")\n",
    "\n",
    "    print(\"Gold Alerts table streaming!\")\n",
    "except Exception as e:\n",
    "    print(f\"Gold Alerts table failed: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"All Gold tables are streaming!\")\n",
    "print(\"Tables created:\")\n",
    "print(\"  1. gold_fraud_summary (complete mode)\")\n",
    "print(\"  2. gold_hourly_patterns (append mode with watermark)\")\n",
    "print(\"  3. gold_high_value_alerts (append mode, no aggregation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gl-md-0004",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "gl-md-0004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Alternative: Simplified Gold Summary (Optional)\n",
    "\n",
    "A simplified version that creates only the fraud summary table with basic aggregations.\n",
    "Use this for testing or if the full Gold pipeline above encounters issues.\n",
    "\n",
    "> **Note:** Only run this if the full pipeline above has not been started,\n",
    "> or after running the cleanup cell first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "gl-code-0003",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "gl-code-0003",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, avg\n",
    "\n",
    "try:\n",
    "    # 1. Read from Silver table\n",
    "    df_silver_stream = spark.readStream \\\n",
    "        .table(\"fraud_lakehouse_workspace.default.silver_transactions\")\n",
    "\n",
    "    # 2. Aggregate\n",
    "    df_gold_summary = df_silver_stream \\\n",
    "        .groupBy(\"Class\") \\\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"Total_Transactions\"),\n",
    "            avg(\"Amount\").alias(\"Average_Amount\")\n",
    "        )\n",
    "\n",
    "    # 3. Write Stream (Complete mode is best for small aggregations)\n",
    "    gold_query = df_gold_summary.writeStream \\\n",
    "        .format(\"delta\") \\\n",
    "        .outputMode(\"complete\") \\\n",
    "        .option(\"checkpointLocation\", gold_checkpoint) \\\n",
    "        .toTable(\"fraud_lakehouse_workspace.default.gold_fraud_summary\")\n",
    "\n",
    "    print(\"Simplified Gold aggregation is running on clean data!\")\n",
    "except Exception as e:\n",
    "    print(f\"Simplified Gold summary failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gl-md-0005",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "gl-md-0005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Verify: Gold Summary Data\n",
    "\n",
    "Query the Gold summary table to confirm fraud and legitimate transaction\n",
    "counts and amounts are being aggregated correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "gl-code-0004",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "gl-code-0004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    display(spark.sql(\"SELECT * FROM fraud_lakehouse_workspace.default.gold_fraud_summary\"))\n",
    "except Exception as e:\n",
    "    print(f\"Failed to query Gold summary: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gl-md-0006",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "gl-md-0006",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "**Gold Layer Status:**\n",
    "- Read from Silver Delta table (streaming)\n",
    "- `gold_fraud_summary` - Aggregated by Class with count, avg, min, max, sum of Amount\n",
    "- `gold_hourly_patterns` - Hourly patterns with 10-minute watermark and 1-hour window\n",
    "- `gold_high_value_alerts` - Alerts for high-value transactions with Critical / High / Medium severity\n",
    "\n",
    "**Pipeline Complete:** Bronze -> Silver -> Gold"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_gold_layer",
   "notebookVersion": "0.0.1"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
